# =============================================================================
# Complete Sales Report Workflow CLI - Real-World End-to-End Analysis (ENHANCED)
# =============================================================================
#
# ENHANCED VERSION with comprehensive assertions for:
# - Specific numeric value validation
# - Formula correctness verification
# - Data integrity checks
# - Multi-step state validation
#
# Calculated expected values (for reference):
# - 10 initial transactions
# - Gross Revenue: $34,200.00
# - Total Discount: $1,930.00
# - Net Revenue: $32,270.00
# - Total Units: 231
# - After 3 new rows: 13 transactions, $43,500.00 gross, $2,440.00 discount
#
# =============================================================================

criteria:
  success_rate: 1  # 100% required

ai_summary:
  enabled: true
  judge_provider: azure-openai-judge

providers:
  - name: azure-openai-gpt5-chat
    type: AZURE
    auth_type: entra_id
    model: gpt-5.1-chat
    baseUrl: "{{AZURE_OPENAI_ENDPOINT}}"
    version: 2025-01-01-preview
    rate_limits:
      requests_per_minute: 60
      tokens_per_minute: 150000
    retry:
      retry_on_429: true
      max_retries: 5
  - name: azure-openai-judge
    type: AZURE
    auth_type: entra_id
    model: gpt-4.1
    baseUrl: "{{AZURE_OPENAI_ENDPOINT}}"
    version: 2025-01-01-preview
    rate_limits:
      requests_per_minute: 60
      tokens_per_minute: 150000
    retry:
      retry_on_429: true
      max_retries: 5

servers:
  - name: excel-cli
    type: cli
    command: "{{CLI_COMMAND}}"
    shell: powershell
    working_dir: "{{TEMP_DIR}}"
    tool_prefix: excel

agents:
  - name: gpt5-chat-agent
    servers:
      - name: excel-cli
    provider: azure-openai-gpt5-chat
    skill:
      path: "{{SKILL_PATH_CLI}}"
      file_access: true
    system_prompt: |
      You are a professional Excel analyst. Execute tasks efficiently using available tools.
      - Make reasonable assumptions for ambiguous requests
      - Format data professionally (headers, tables, proper formatting)
      - Use the Data Model for analysis, not manual calculations
      - Always verify row counts and data completeness
      - Report specific numeric values (not just descriptions)
    clarification_detection:
      enabled: true
      judge_provider: azure-openai-judge

settings:
  verbose: true
  max_iterations: 25


sessions:
  # ======================================================================
  # PART 1: Load Data and Create Foundation
  # ======================================================================
  - name: "Sales Report - Part 1: Load Data"
    tests:
      - name: "Load sales data and establish data model"
        prompt: |
          I need to analyze our Q1 2025 sales data. Let me build a professional sales analysis workbook.

          Step 1 - Create the workbook:
          Create a new Excel file at {{TEMP_DIR}}/sales-analysis-q1-cli-{{randomValue type='UUID'}}.xlsx

          Step 2 - Enter Sales Raw Data (into Sales sheet):
          Enter this transaction-level data starting at A1:

          TransactionID, Date, Region, Product, Salesperson, Quantity, UnitPrice, Discount
          T001, 2025-01-05, North, Laptop Pro, Alice, 5, 1200, 0.05
          T002, 2025-01-06, North, Mouse Wireless, Alice, 50, 25, 0
          T003, 2025-01-08, South, Laptop Pro, Bob, 3, 1200, 0.1
          T004, 2025-01-12, South, Monitor 4K, Bob, 8, 450, 0.05
          T005, 2025-01-15, East, Keyboard Mechanical, Carol, 30, 120, 0
          T006, 2025-01-18, North, Monitor 4K, Alice, 4, 450, 0
          T007, 2025-01-22, East, Laptop Pro, Carol, 6, 1200, 0.1
          T008, 2025-01-25, West, Mouse Wireless, Dave, 100, 25, 0.1
          T009, 2025-02-01, South, Monitor 4K, Bob, 5, 450, 0
          T010, 2025-02-05, North, Keyboard Mechanical, Alice, 20, 120, 0.05

          CRITICAL: To avoid PowerShell JSON parsing issues, you MUST:
          - Write the data as a JSON file first (e.g., using Out-File)
          - Then use --values-file <path> instead of --values with inline JSON

          Step 3 - Create Sales Table and Regional Summary:
          - Convert the sales data (A1:H11) into an Excel Table called "SalesTransactions"
          - Create a new sheet called Summary
          - In the Summary sheet, create a simple table showing: Region (unique values from Sales),
            Transaction Count, Total Revenue (before discount)
          - Calculate Total Revenue: Sum of (Quantity * UnitPrice) for all rows

          Step 4 - Validate:
          - Confirm the SalesTransactions table has exactly 10 data rows (plus header)
          - Report the exact total gross revenue amount (sum of Quantity * UnitPrice)
          - List all 4 regions found in the data: North, South, East, West
          - Verify no calculation errors (row count should match)

        assertions:
          - type: cli_exit_code_equals
            expected: 0
          - type: no_clarification_questions

          # Specific row count validation
          - type: output_contains
            text: "10"

          # Specific revenue validation (allow small rounding variance)
          - type: output_regex
            pattern: '\$?34[\,.]?200(\.[0]{1,2})?'

          # Verify all regions present
          - type: output_contains
            text: "North"
          - type: output_contains
            text: "South"
          - type: output_contains
            text: "East"
          - type: output_contains
            text: "West"

  # ======================================================================
  # PART 2: Create Data Model and Measures
  # ======================================================================
  - name: "Sales Report - Part 2: Build Data Model"
    tests:
      - name: "Build Data Model with DAX measures"
        prompt: |
          Great! Now let me set up the Data Model for deeper analysis.

          IMPORTANT: First, use the excel session list command to discover which Excel file we have open.
          Then use that file path for all subsequent operations.

          IMPORTANT: Do NOT ask clarifying questions. If the relationship creation fails due to type mismatch,
          format both Date columns as Date in the worksheet and retry. If it still fails, proceed without the
          relationship and continue with measures and verification.

          Step 1 - Add to Data Model:
          - Add the SalesTransactions table to the Data Model
          - Create a Date dimension table in a new sheet called "DimDate" with 20 unique dates.
            Use this exact list (Date column, A2:A21):
            2025-01-05, 2025-01-06, 2025-01-08, 2025-01-12, 2025-01-15,
            2025-01-18, 2025-01-22, 2025-01-25, 2025-02-01, 2025-02-05,
            2025-01-07, 2025-01-09, 2025-01-10, 2025-01-11, 2025-01-13,
            2025-01-14, 2025-01-16, 2025-01-17, 2025-01-19, 2025-01-20
          - Add DimDate to the Data Model
          - Create a relationship: SalesTransactions[Date] â†’ DimDate[Date]
          - Verify the relationship was created successfully
          - Do not loop on reading the Sales date column; set DimDate once and proceed

          Step 2 - Create Measures (in SalesTransactions):
          Create these DAX measures exactly as specified:
          - Revenue (Gross) = SUM(SalesTransactions[Quantity] * SalesTransactions[UnitPrice])
          - Discount Amount = SUM(SalesTransactions[Quantity] * SalesTransactions[UnitPrice] * SalesTransactions[Discount])
          - Revenue (Net) = [Revenue (Gross)] - [Discount Amount]
          - Unit Total = SUM(SalesTransactions[Quantity])
          - Average Order Value = DIVIDE([Revenue (Net)], COUNTROWS(SalesTransactions), 0)

          Step 3 - Verify Measure Values:
          - Query the Data Model to get exact values for each measure:
            * Revenue (Gross) should be exactly $34,200.00
            * Discount Amount should be exactly $1,930.00
            * Revenue (Net) should be exactly $32,270.00
            * Unit Total should be exactly 231 units
            * Average Order Value should be $3,227.00 (or $3,227 rounded)
          - Report each measure value with full precision
          - If a DAX query fails, compute the value directly from the SalesTransactions table and still report the exact numbers.

        assertions:
          - type: cli_exit_code_equals
            expected: 0
          - type: no_clarification_questions

          # Specific measure value assertions
          - type: output_regex
            pattern: 'Revenue.*Gross|Gross.*Revenue'
          - type: output_regex
            pattern: '\$?34[\,.]?200[\.]?00|34200\.00|34200'

          - type: output_contains
            text: "Discount Amount"
          - type: output_regex
            pattern: '\$?1[\,.]?930[\.]?00|1930\.00|1930'

          - type: output_contains
            text: "Revenue (Net)"
          - type: output_regex
            pattern: '\$?32[\,.]?270[\.]?00|32270\.00|32270'

          - type: output_contains
            text: "Unit Total"
          - type: output_regex
            pattern: '231'

          - type: output_contains
            text: "Average Order Value"
          - type: output_regex
            pattern: '3[.,]?227'  # Approximately $3,227

  # ======================================================================
  # PART 3: Create Analysis Views (PivotTables)
  # ======================================================================
  - name: "Sales Report - Part 3: Create PivotTables"
    tests:
      - name: "Create analysis dashboards with PivotTables"
        prompt: |
          Perfect! Now let me create analysis views.

          IMPORTANT: First, use the excel session list command to discover which Excel file we have open.
          Then use that file path for all subsequent operations.

          IMPORTANT: Before creating PivotTables, use excel table list or read to confirm the SalesTransactions table exists.

          Create two PivotTables from the SalesTransactions table:

          PivotTable 1 - "Revenue by Region":
          - Destination: New sheet called "AnalysisRegion"
          - Row Fields: Region (top level), Product (nested)
          - Data Fields: Sum of Quantity, Sum of Revenue (Gross)
          - Format professionally with number formatting for currency

          PivotTable 2 - "Salesperson Performance":
          - Destination: New sheet called "AnalysisSales"
          - Row Fields: Salesperson
          - Data Fields: Sum of Quantity, Sum of Revenue (Net), Count of TransactionID
          - Apply conditional formatting to Revenue (Net) column, green for highest values
          - Sort by Revenue (Net) descending

          Step 2 - Analyze Results:
          Based on the PivotTables, provide SPECIFIC VALUES for:
          - Who is our top salesperson by net revenue? (Provide exact surname and revenue amount)
          - Which region has the most transactions? (Provide region name and exact count)
          - What's the total quantity sold across all regions? (Provide exact number: 231)
          - Rank all 4 salespeople by revenue (highest to lowest with specific amounts)
          - Rank all 4 regions by revenue (highest to lowest with specific amounts)

          IMPORTANT: If PivotTables do not expose net revenue, run a DAX query against the Data Model to get net revenue by salesperson
          (e.g., EVALUATE ADDCOLUMNS(SUMMARIZE(SalesTransactions, SalesTransactions[Salesperson]), "NetRevenue", [Revenue (Net)]))
          and use those numbers in your report. Ensure you explicitly state Alice's net revenue as $11,030.00.

          Important: Provide specific numeric values, not just descriptions.

        assertions:
          - type: cli_exit_code_equals
            expected: 0
          - type: no_clarification_questions

          # Specific salesperson validation
          - type: output_contains
            text: "Alice"  # Top by revenue ($11,030.00)
          - type: output_regex
            pattern: '\$?11[\,.]?030[\.]?00|11030\.00|11030'

          # Total quantity validation
          - type: output_contains
            text: "231"

          # Region validation
          - type: output_contains
            text: "Region"
          - type: output_contains
            text: "North"  # Has most transactions (5)

          # Data integrity: should mention all 4 salespeople
          - type: output_contains
            text: "Alice"
          - type: output_contains
            text: "Bob"
          - type: output_contains
            text: "Carol"
          - type: output_contains
            text: "Dave"

  # ======================================================================
  # PART 4: Incremental Update and Validation
  # ======================================================================
  - name: "Sales Report - Part 4: Handle New Data"
    tests:
      - name: "Handle new data and update analysis"
        prompt: |
          We just received additional February data!

          IMPORTANT: First, use the excel session list command to discover which Excel file we have open.
          Then use that file path for all subsequent operations.

          Add these three new transactions to the SalesTransactions table:

          T011, 2025-02-10, East, Laptop Pro, Carol, 4, 1200, 0.05
          T012, 2025-02-15, South, Keyboard Mechanical, Bob, 15, 120, 0
          T013, 2025-02-20, West, Monitor 4K, Dave, 6, 450, 0.1

          Then:
          - Refresh all PivotTables to include the new data
          - Verify the SalesTransactions table now has EXACTLY 13 rows (10 original + 3 new)
          - Query the Data Model to get the UPDATED revenue figures:
            * New Gross Revenue should be $43,500.00 (up from $34,200.00)
            * New Discount should be $2,440.00 (up from $1,930.00)
            * New Net Revenue should be $41,060.00 (up from $32,270.00)
          - Check if any salesperson rankings changed
          - Verify PivotTables use the new total (13 transactions, not 10)

          Important: Do NOT delete and recreate the tables. Use targeted inserts and refreshes only.

        assertions:
          - type: cli_exit_code_equals
            expected: 0
          - type: no_clarification_questions

          # Row count validation - CRITICAL
          - type: output_contains
            text: "13"

          # Updated revenue validation
          - type: output_regex
            pattern: '\$?43[\,.]?500[\.]?00|43500\.00|43500'

          # Updated discount validation
          - type: output_regex
            pattern: '\$?2[\,.]?440[\.]?00|2440\.00|2440'

          # Updated net revenue validation
          - type: output_regex
            pattern: '\$?41[\,.]?060[\.]?00|41060\.00|41060'

          # Verify refresh occurred
          - type: output_regex
            pattern: '(?i)(refresh|updated|refreshed)'

  # ======================================================================
  # PART 5: Final Validation and Summary
  # ======================================================================
  - name: "Sales Report - Part 5: Final Validation"
    tests:
      - name: "Final validation and save"
        prompt: |
          Perfect! Let me do a final comprehensive check and save our report.

          IMPORTANT: First, use the excel session list command to discover which Excel file we have open.
          Then use that file path for all subsequent operations.

          Step 1 - Structure Verification:
          1. List all sheets in the workbook (should be 5): Sales, Summary, DimDate, AnalysisRegion, AnalysisSales
          2. Verify the SalesTransactions table has EXACTLY 13 data rows (plus header = 14 rows total)
          3. Verify the DimDate table has 20 unique dates
          4. Confirm no formulas exist in raw data columns (Quantity, UnitPrice, Discount should be values only)
             - Use excel range get-formulas on Sales!B2:D14 to verify these columns contain values only.
          5. Confirm formulas/measures exist IN the Data Model

          IMPORTANT: In your response, explicitly include the phrase "13 rows" when reporting the SalesTransactions row count.

          Step 2 - Final Revenue Report:
          Get the absolute final numbers (use a DAX query or compute directly from SalesTransactions A2:H14):
          - Total Gross Revenue across all 13 transactions: $43,500.00
          - Total Discounts: $2,440.00
          - Total Net Revenue: $41,060.00
          - Total Units Sold: 256 (231 + 25)
          IMPORTANT: If your DAX query returns earlier values (e.g., $34,200), recompute from the table and report the correct totals above.

          Step 3 - Salesperson Deep Dive (by Net Revenue):
          - Rank all salespersons by Net Revenue (highest to lowest)
          - Report exact revenue for each: Alice, Bob, Carol, Dave
          - Include transaction count and unit count for each

          Step 4 - Region Deep Dive:
          - Rank all regions by revenue (highest to lowest)
          - Show transaction count and unit count for each region

          Then save the workbook to ensure all changes are persisted.

          Report your findings in a structured format.

        assertions:
          - type: cli_exit_code_equals
            expected: 0
          - type: no_clarification_questions

          # Sheet count/names
          - type: output_contains
            text: "5"  # 5 sheets
          - type: output_contains
            text: "Sales"
          - type: output_contains
            text: "Summary"
          - type: output_contains
            text: "DimDate"
          - type: output_contains
            text: "AnalysisRegion"
          - type: output_contains
            text: "AnalysisSales"

          # Row count validation
          - type: output_contains
            text: "13"
          - type: output_regex
            pattern: '(?i)(13 data rows|13 rows|13 transactions)'

          # Final revenue figures - CRITICAL VALIDATION
          - type: output_regex
            pattern: '\$?43[\,.]?500[\.]?00|43500\.00|43500'
          - type: output_regex
            pattern: '\$?2[\,.]?440[\.]?00|2440\.00|2440'
          - type: output_regex
            pattern: '\$?41[\,.]?060[\.]?00|41060\.00|41060'

          # Units validation
          - type: output_regex
            pattern: '(?i)(256 units|total.*256|\b256\b)'

          # Salesperson coverage (all 4 must be mentioned with specific amounts)
          - type: output_contains
            text: "Alice"
          - type: output_contains
            text: "Bob"
          - type: output_contains
            text: "Carol"
          - type: output_contains
            text: "Dave"

          # Save confirmation
          - type: output_regex
            pattern: '(?i)(save|saved|persistence|workbook)'
